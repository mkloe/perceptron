{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f29b52c3",
   "metadata": {},
   "source": [
    "# Creating a model perceptron working on 2 variables Iris and saving into the file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be1677c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting perceptron.py\n"
     ]
    }
   ],
   "source": [
    "%%file perceptron.py\n",
    "\n",
    "#import of libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "#Model of perceptron\n",
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, eta=0.1, n_iter=10):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.w_ = np.zeros(1 + X.shape[1])\n",
    "        self.errors_ = []\n",
    "        \n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_[1:] += update * xi\n",
    "                self.w_[0] += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.where(self._net_input(X) >= 0, 1, -1)\n",
    "    \n",
    "    def _net_input(self, X):\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "#import of data\n",
    "iris = load_iris()\n",
    "iris.keys()\n",
    "\n",
    "#data transformation\n",
    "df = pd.DataFrame(data=np.c_[iris['data'], iris['target']], \n",
    "                  columns=iris['feature_names']+['target'])\n",
    "df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n",
    "df = df.drop(columns=['target'])\n",
    "df['species'] = np.where(df['species'] == 'setosa',-1,1)\n",
    "df = df[0:100]\n",
    "df = df.sample(frac=1)\n",
    "df_X = df.iloc[:,[0,2]]\n",
    "df_y = df.iloc[:,4]\n",
    "\n",
    "#division into train and test dataset\n",
    "X_train = df_X[:int(df_X.shape[0]*0.7)]\n",
    "X_test = df_X[int(df_X.shape[0]*0.7):]\n",
    "y_train = df_y[:int(df_y.shape[0]*0.7)]\n",
    "y_test = df_y[int(df_X.shape[0]*0.7):]\n",
    "\n",
    "#import of the object\n",
    "model = Perceptron()\n",
    "\n",
    "#training of the perceptron\n",
    "model.fit(X_train.values, y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958346d3",
   "metadata": {},
   "source": [
    "# Flask server allowing for a request with 2 params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "444e769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7362649c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting zadanie.py\n"
     ]
    }
   ],
   "source": [
    "%%file server.py\n",
    "\n",
    "from flask import Flask\n",
    "from flask import request\n",
    "from perceptron import *\n",
    "\n",
    "\n",
    "# Create a flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Create an API end point\n",
    "@app.route('/hello', methods=['GET'])\n",
    "def function():\n",
    "    \n",
    "    #parameters - user adds a name and decides if the w parameter is passed in response\n",
    "    name = request.args.get(\"name\", \"\")\n",
    "    param_errors = bool(request.args.get(\"errors\", \"\"))\n",
    "    param_w = bool(request.args.get(\"w\", \"\"))\n",
    "    \n",
    "    #parameters values\n",
    "    if name:\n",
    "        welcome = f\"Hello {name}, here are your prediction results\"\n",
    "    else:\n",
    "        welcome = f\"Hello, here are your prediction results\"\n",
    "    prediction = model.predict(X_test).tolist()\n",
    "    errors = model.errors_\n",
    "    w = model.w_.tolist()\n",
    "    \n",
    "    #response\n",
    "    if param_errors == True and param_w == True:\n",
    "        resp1 = {'welcome': welcome, 'prediction': prediction, 'errors': errors, 'w' : w}\n",
    "    elif param_errors == True and param_w != True:\n",
    "        resp1 = {'welcome': welcome, 'prediction': prediction, 'errors': errors}\n",
    "    elif param_errors != True and param_w == True:\n",
    "        resp1 = {'welcome': welcome, 'prediction': prediction, 'w' : w}\n",
    "    elif param_errors!= True and param_w != True:\n",
    "        resp1 = {'welcome': welcome, 'prediction': prediction}\n",
    "    \n",
    "    #return\n",
    "    return resp1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d9442a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"zadanie\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "#open the port\n",
    "p1 = subprocess.Popen([\"python\", \"zadanie.py\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e0e6c0",
   "metadata": {},
   "source": [
    "# Flask server response including model prediction and relevant data in a json format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b072ed2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [27/Apr/2022 22:38:19] \"GET /hello?name=marcin&w=True&errors=True HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'{\"errors\":[7,0,0,0,0,0,0,0,0,0],\"prediction\":[1,1,-1,1,1,1,1,-1,-1,1,-1,-1,-1,1,-1,1,1,-1,-1,1,-1,-1,1,1,1,-1,-1,-1,-1,1],\"w\":[-0.2,-0.48,1.16],\"welcome\":\"Hello marcin, here are your prediction results\"}\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the response\n",
    "response = requests.get(\"http://127.0.0.1:5000/hello?name=marcin&w=True&errors=True\")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e28517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kill the process\n",
    "p1.kill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe679a1",
   "metadata": {},
   "source": [
    "# Saving the response to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74fa0fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "json_response = json.loads(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c18e6058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///perceptron.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb71317e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "from perceptron import *\n",
    "df = X_test\n",
    "df['prediction'] = json_response['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70076e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to database\n",
    "df.to_sql('perceptron2', con=engine, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3409180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1,), (1,), (-1,), (1,), (1,), (1,), (1,), (-1,), (-1,), (1,), (-1,), (-1,), (-1,), (1,), (-1,), (1,), (1,), (-1,), (-1,), (1,), (-1,), (-1,), (1,), (1,), (1,), (-1,), (-1,), (-1,), (-1,), (1,)]\n",
      "[(6.3, 4.9, 1), (5.1, 1.5, 1), (4.8, 1.6, -1), (5.5, 1.4, 1), (5.5, 4.0, 1), (5.4, 1.7, 1), (5.5, 3.8, 1), (4.4, 1.4, -1), (5.9, 4.2, -1), (5.1, 1.5, 1), (5.5, 4.0, -1), (5.8, 4.1, -1), (6.8, 4.8, -1), (5.1, 3.0, 1), (4.8, 1.6, -1), (5.6, 3.9, 1), (5.6, 3.6, 1), (4.9, 1.5, -1), (5.0, 1.4, -1), (5.1, 1.7, 1), (6.1, 4.0, -1), (6.0, 4.5, -1), (4.6, 1.4, 1), (5.3, 1.5, 1), (5.8, 1.2, 1), (6.3, 4.7, -1), (6.6, 4.6, -1), (5.7, 4.2, -1), (5.5, 3.7, -1), (5.0, 3.3, 1)]\n"
     ]
    }
   ],
   "source": [
    "#check if the results are in db\n",
    "a = engine.execute('select prediction from perceptron2').fetchall()\n",
    "b = engine.execute('select * from perceptron2').fetchall()\n",
    "print (a)\n",
    "print(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
